# -*- coding: utf-8 -*-
"""MobileNet Testing with CIFAR-10

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1DWCHsn9VHui-Gsc4_nKugmuj2JLTQIyI
"""

# Library Import
import tensorflow as tf
import tensorflow.keras

from tensorflow.keras.layers import Conv2D, DepthwiseConv2D,Flatten, Dense, AveragePooling2D, ReLU, BatchNormalization, Add, Input
from tensorflow.keras.datasets.cifar10 import load_data
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.models import Model
from tensorflow.keras.preprocessing.image import ImageDataGenerator
import numpy as np

# data normalization

def data_normalization(train_data, test_data):
    train_data = train_data.astype('float32') / 255
    test_data = test_data.astype('float32') / 255
    return train_data, test_data

# Label one-hot encoding
def OneHotEncoding(train_target, test_target):
    train_target = to_categorical(train_target, len(np.unique(train_target)))
    test_target = to_categorical(test_target, len(np.unique(test_target)))
    return train_target, test_target

def load_cifar10():
    (train_data, train_target), (test_data, test_target) = load_data()
    train_data, test_data = data_normalization(train_data, test_data)
    train_target, test_target = OneHotEncoding(train_target, test_target)

    seed = 123
    np.random.seed(seed)
    np.random.shuffle(train_data)
    np.random.seed(seed)
    np.random.shuffle(train_target)
    return train_data, train_target, test_data, test_target

# Data loading
train_data, train_target, test_data, test_target = load_cifar10()

train_target[0]

# Depthwise Seperable Convolution Block

def MobileBlock(inputs, out_channel, stride=1, use_bias=True):
    
    DWConv_1 = DepthwiseConv2D(3, strides=stride, padding='same', use_bias=use_bias)(inputs)
    BN_1 = BatchNormalization()(DWConv_1)
    ReLu_1 = ReLU()(BN_1)
    
    Conv_2 = Conv2D(out_channel, 1, strides=1, padding='same', use_bias=use_bias)(ReLu_1)
    BN_2 = BatchNormalization()(Conv_2)
    ReLu_2 = ReLU()(BN_2)
    
    return ReLu_2

def MobileNet(shape=(32,32,3), num=30, multiplier=1, use_bias=True):
    inputs = Input(shape=shape)
    out_channel = 16
    
    Conv_1 = Conv2D(out_channel, 3, 1, padding='same', use_bias=use_bias)(inputs)
    BN_1 = BatchNormalization()(Conv_1)
    ReLu_1 = ReLU()(BN_1)
    
    MobileNet_1 = ReLu_1
    for i in range(num):
        MobileNet_1 = MobileBlock(MobileNet_1, out_channel * multiplier, stride=1, use_bias=use_bias)
        
    MobileNet_2 = MobileBlock(MobileNet_1, out_channel*2 * multiplier, stride=2, use_bias=use_bias)
    for i in range(1,num):
        MobileNet_2 = MobileBlock(MobileNet_2, out_channel*2 * multiplier, stride=1, use_bias=use_bias)
    
    MobileNet_3 = MobileBlock(MobileNet_2, out_channel*4 * multiplier, stride=2, use_bias=use_bias)
    for i in range(1,num):
        MobileNet_3 = MobileBlock(MobileNet_3, out_channel*4 * multiplier, stride=1, use_bias=use_bias)
    
    AP = AveragePooling2D((8,8))(MobileNet_3)
    flatten = Flatten()(AP)
    dense = Dense(10, activation='softmax')(flatten)
    
    return Model(inputs=inputs, outputs=dense, name="{mul}_MobileNet{depth}".format(mul=multiplier, depth=(6*num + 2)))

def Conv_MobileBlock(inputs, out_channel, stride=1, use_bias=True):
    Conv_1 = Conv2D(out_channel, 3, strides=stride, padding='same', use_bias=use_bias)(inputs)
    BN_1 = BatchNormalization()(Conv_1)
    ReLu_1 = ReLU()(BN_1)
    
    # Conv_2 = Conv2D(out_channel, 3, strides=1, padding='same', use_bias=use_bias)(ReLu_1)
    # BN_2 = BatchNormalization()(Conv_2)
    # ReLu_2 = ReLU()(BN_2)
    
    return ReLu_1

def Conv_MobileNet(shape=(32,32,3), num=3, use_bias=True):
    inputs = Input(shape=shape)
    out_channel = 16 
    
    Conv_1 = Conv2D(out_channel, 3, 1, padding='same', use_bias=use_bias)(inputs)
    BN_1 = BatchNormalization()(Conv_1)
    ReLu_1 = ReLU()(BN_1)
    
    Conv_MobileNet_1 = ReLu_1
    for i in range(num):
        Conv_MobileNet_1 = Conv_MobileBlock(Conv_MobileNet_1, out_channel, 1, use_bias)
    
    Conv_MobileNet_2 = Conv_MobileBlock(Conv_MobileNet_1, out_channel*2, 2, use_bias)
    for i in range(1,num):
        Conv_MobileNet_2 = Conv_MobileBlock(Conv_MobileNet_2, out_channel*2, 1, use_bias)
    
    Conv_MobileNet_3 = Conv_MobileBlock(Conv_MobileNet_2, out_channel*4, 2, use_bias)
    for i in range(1,num):
        Conv_MobileNet_3 = Conv_MobileBlock(Conv_MobileNet_3, out_channel*4, 1, use_bias)
    AP = AveragePooling2D((8,8))(Conv_MobileNet_3)
    flatten= Flatten()(AP)
    dense = Dense(10, activation='softmax')(flatten)
    
    return Model(inputs=inputs, outputs=dense, name="Conv_MobileNet{}".format(3*num + 2))

conv_mobilenet = Conv_MobileNet(num=10)

conv_mobilenet.summary()

# Train Setting

# Learning Rate Scheduler

def lr_schedule(epoch,lr):
    lr = 0.1
    if epoch >= 40:
        lr = 0.01
    if epoch >= 70:
        lr = 0.001
    return lr

# Test Error metrics
def TestError(y_true, y_pred):
    accuracy = tf.keras.metrics.categorical_accuracy(y_true, y_pred)
    return (1 - accuracy) * 100

optimizer = tf.keras.optimizers.RMSprop()

lr_callback = tf.keras.callbacks.LearningRateScheduler(lr_schedule)

conv_mobilenet.compile(optimizer, tf.keras.losses.CategoricalCrossentropy(), metrics=['acc', TestError])

hist = conv_mobilenet.fit(train_data, train_target, batch_size=128, epochs=100, validation_data=(test_data, test_target))
                    #,callbacks=[lr_callback])

mobilenet = MobileNet(num=10)

mobilenet.summary()

mobilenet.compile(optimizer, tf.keras.losses.CategoricalCrossentropy(), metrics=['acc', TestError])

hist = mobilenet.fit(train_data, train_target, batch_size=128, epochs=100, validation_data=(test_data, test_target))
                     #callbacks=[lr_callback])

mobilenet_2 = MobileNet(num=10, multiplier=0.75)
mobilenet_2.summary()

mobilenet_2.compile(optimizer, tf.keras.losses.CategoricalCrossentropy(), metrics=['acc', TestError])
hist = mobilenet_2.fit(train_data, train_target, batch_size=128, epochs=100, validation_data=(test_data, test_target))
                    #  callbacks=[lr_callback])

mobilenet_3 = MobileNet(num=10, multiplier=0.5)
mobilenet_3.summary()

mobilenet_3.compile(optimizer, tf.keras.losses.CategoricalCrossentropy(), metrics=['acc', TestError])
hist = mobilenet_3.fit(train_data, train_target, batch_size=128, epochs=100, validation_data=(test_data, test_target))
                    #  callbacks=[lr_callback])

mobilenet_4 = MobileNet(num=10, multiplier=0.25)
mobilenet_4.summary()

mobilenet_4.compile(optimizer, tf.keras.losses.CategoricalCrossentropy(), metrics=['acc', TestError])
hist = mobilenet_4.fit(train_data, train_target, batch_size=128, epochs=100, validation_data=(test_data, test_target))
                    #  callbacks=[lr_callback])

from keras.utils import plot_model
plot_model(mobilenet, to_file='model.png')

